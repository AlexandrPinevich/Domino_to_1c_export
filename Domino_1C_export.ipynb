{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandrPinevich/Domino_to_1c_export/blob/main/Domino_1C_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgesjLMBFOou"
      },
      "source": [
        "## Эта штука должна парсить csv и исходники и рожать из них данные на вход в 1С для ввода начальных остатков. Файлы берутся из гугл диска. Для целей консистентности данных сильно желательно все файлы выгружать из Домина одним днем и одним пакетом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w--yulQ0uOwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cbeba39-9741-40b6-9680-497c2f8e9f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.9-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.9\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd            #БЕЗ ЭТОГО РАБОТАТЬ НЕ БУДЕТ!!!\n",
        "from datetime import datetime  #НАДО ЗАПУСКАТЬ ПЕРЕД ОБРАБОТКОЙ\n",
        "import pytz                    #ВООБЩЕ ВСЕ ПО ОЧЕРЕДИ НАДО ЗАПУСКАТЬ\n",
        "!pip install xlsxwriter        #ИНАЧЕ ЭКСЕЛЬ НЕ ПИШЕТСЯ ИЗ-ЗА КОДИРОВКИ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пути\n",
        "input_path = '/content/drive/MyDrive/Colab Notebooks/Input/'\n",
        "output_path = '/content/drive/MyDrive/Colab Notebooks/Output/'\n",
        "time_now = '_' + (datetime.now(pytz.timezone('Europe/Moscow'))\\\n",
        "          .strftime(\"%Y_%b_%d %H.%M.%S\"))\n",
        "to_xlsx = '.xlsx'\n",
        "to_csv = '.csv'"
      ],
      "metadata": {
        "id": "L7ISX1nV_yPn"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CD304lqmzt4"
      },
      "source": [
        "## Блок считывания файлов. Папка Input\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "sb8LITeDmi0f"
      },
      "outputs": [],
      "source": [
        "# Это читает ИСХОДНИК текущий партии\n",
        "# предобработанный, но без ручной колонки партий\n",
        "file_name = '!!!!Исходник текущий партии.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "batch=pd.read_excel(file_name,header = 4, skipfooter = 1, keep_default_na=True\\\n",
        "                    , dtype={'ТОВАР': object}, sheet_name='gr_post')\n",
        "batch.rename(columns={'ТОВАР': 'Партия'}, inplace=True)\n",
        "batch.rename(columns={'ЕИ': 'ЕИпартии'}, inplace=True)\n",
        "batch.insert(0,'ТОВАР','')\n",
        "batch['ТОВАР'] = batch['Партия'].astype('Float64').astype('Int64')\n",
        "batch.insert(2,'Номенклатура','')\n",
        "batch['Номенклатура'] = 'ДМ-' + batch['ТОВАР'].apply('{:0>8}'.format)\\\n",
        "                                                             .astype(str)\n",
        "batch.dropna(subset=['ИСХ_КОЛИЧ'], inplace = True)\n",
        "# Дропает строки без остатка насовсем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Fbz9TbYjM2bN"
      },
      "outputs": [],
      "source": [
        "# Это читает ИСХОДНИК текущий уже экселем предобработанный\n",
        "file_name = '!!!!Исходник текущий.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "df2=pd.read_excel(file_name, header = 4, skipfooter = 1, keep_default_na=True\\\n",
        "                  , sheet_name='gr_post')\n",
        "df2.insert(1,'Номенклатура','')\n",
        "df2['Номенклатура'] = 'ДМ-' + df2['ТОВАР'].apply('{:0>8}'.format).astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lfXKsFfbTQVy"
      },
      "outputs": [],
      "source": [
        "# Это читает файл ###Справочники\n",
        "file_name = '###Справочники.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "unitsDf=pd.read_excel(file_name, sheet_name='units', keep_default_na=True\\\n",
        "                          , dtype={'КодЕд': object})\n",
        "managersDf=pd.read_excel(file_name, sheet_name='managers', keep_default_na=True)\n",
        "warehousesDf=pd.read_excel(file_name, sheet_name='warehouses'\\\n",
        "                          , keep_default_na=True)\n",
        "batch_statusDf=pd.read_excel(file_name, sheet_name='batch_status'\\\n",
        "                          , keep_default_na=True)\n",
        "suppliersDf=pd.read_excel(file_name, sheet_name='suppliers'\\\n",
        "                          , keep_default_na=True\\\n",
        "                          , dtype={'Поставщик_Номер_в_Домино': object})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "UfUe6_j44Oxr"
      },
      "outputs": [],
      "source": [
        "# Это читает BARCODES.CSV сырой, как выпал из отчета Домино\n",
        "# keep_default_na = 1/0 ПЕРЕКЛЮЧАТЕЛЬ ВЫВОДА NaN\n",
        "file_name = 'barcodes.csv'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "header_list = ['ТОВАР','Штрихкод','ТОВАР2','НАИМЕНОВАНИЕ_ДЛИННОЕ',\n",
        "          'АРТИКУЛ_ДЛИННЫЙ','GrNum','Group','SrgNum','SubGroupeAsIs',\n",
        "          'supplierCode','supplier','countryCode','country']\n",
        "\n",
        "df1 = pd.read_csv(file_name, delimiter = ';', header=None, names = header_list,\n",
        "            encoding='Windows-1251')\n",
        "#,header=None, header=None, iterator = False, index_col = False, \n",
        "# , engine='c''pyarrow', nrows=100 keep_default_na=True,, low_memory=False\n",
        "\n",
        "df1.insert(1,'Номенклатура','')\n",
        "df1['Номенклатура'] = 'ДМ-' + df1['ТОВАР'].apply('{:0>8}'.format).astype(str)\n",
        "df1['SubGroupe'] = df1['SubGroupeAsIs'].str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ZANy-leO1ARe"
      },
      "outputs": [],
      "source": [
        "# Это читает SKU из 1С нужно чтобы только новые карточки можно было добавить\n",
        "# или страрые удалить\n",
        "file_name = 'SKU from 1C.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "from1c = pd.read_excel(file_name, sheet_name='TDSheet')\n",
        "from1c['Номенклатура'] ='ДМ-' + from1c['Код Домино'].apply('{:0>8}'.format)\\\n",
        "    .astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "kl0yPbCByiWP"
      },
      "outputs": [],
      "source": [
        "# Это читает Категории из 1С \n",
        "file_name = 'Категории из 1С.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "catalog1c=pd.read_excel(file_name,sheet_name='TDSheet')\n",
        "catalog1c['SubGroupe'] = catalog1c['Подгруппа']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nBWD1jN3fwj"
      },
      "source": [
        "## Блок обработки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-1hcfBB_AzDV"
      },
      "outputs": [],
      "source": [
        "# Фрейм BarNoDup Убирает дубликаты строк из df1 - BARCODES.CSV по коду,\n",
        "# нужно для корректного джойна с исходником\n",
        "BarNoDup = df1.copy(deep=True).drop_duplicates(subset=['ТОВАР'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Bup5qnn_sYSF"
      },
      "outputs": [],
      "source": [
        "# Фрейм BarcodeExport Забираем из таблицы с штрихкодами 2 колонки\n",
        "# в новый датафрейм BarcodeExport для последующей выгрузки\n",
        "BarcodeExport = df1[['Номенклатура', 'Штрихкод']].copy(deep=True)\n",
        "BarcodeExport = BarcodeExport.merge(df2['Номенклатура'], how='inner')\n",
        "# Оставить только совпавшие c исходником строки,\n",
        "# Нюансик, строки без штрихкода дропаются тоже how='inner'                                                                   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-5KMhQfhl7pH"
      },
      "outputs": [],
      "source": [
        "# Фрейм skuDf копирует исходник чтобы избежать возможного конфликта\n",
        "# последовательности загрузки, в нем же добавляем колонки, кот. нужны на импорт\n",
        "# а не надо здесь ешё наличие штрихкода в домине проверить к этим карточкам?\n",
        "skuDf = df2.copy(deep=True)\n",
        "skuDf = skuDf\\\n",
        "    .merge(BarNoDup[['НАИМЕНОВАНИЕ_ДЛИННОЕ','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['АРТИКУЛ_ДЛИННЫЙ','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['SubGroupe','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(unitsDf[['КодЕд','ЕИ']], on='ЕИ', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Имя','ПОСТАВЩИК']]\\\n",
        "           , on='ПОСТАВЩИК', how='left')\\\n",
        "    .merge(managersDf[['Мен1С','МЕНЕДЖЕР']], on='МЕНЕДЖЕР', how='left')\\\n",
        "    .merge(catalog1c, left_on='SubGroupe', right_on='SubGroupe', how='left')\n",
        "\n",
        "skuDf.insert(36,'Наименование полное','')\n",
        "skuDf['Наименование полное'] = skuDf['НАИМЕНОВАНИЕ_ДЛИННОЕ']\n",
        "skuDf['Направление деятельности'] = 'Основное направление'\n",
        "skuDf['Использовать партии'] = 'Да'\n",
        "skuDf['Обязательное заполнение партий'] = 'Да'\n",
        "skuDf['Нижняя граница остатков'] = skuDf['МИН'].abs()\n",
        "skuDf['Верхняя граница остатков'] = skuDf['УП'].abs()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J2-AiAxJuLnf"
      },
      "outputs": [],
      "source": [
        "# Фрейм SKUexport Забираем из skuDf нужные колонки и переименовываем \n",
        "# для последующей выгрузки в файл\n",
        "SKUexport =skuDf[['Номенклатура', 'НАИМЕНОВАНИЕ_ДЛИННОЕ',\n",
        "       'Наименование полное','АРТИКУЛ_ДЛИННЫЙ', 'SubGroupe', 'КодЕд',\n",
        "       'Поставщик_Имя', 'Тип номенклатуры по умолчанию', 'Вид ставки НДС',\n",
        "       'Способ списания', 'Счет учета запасов', 'Счет учета затрат',\n",
        "       'Способ пополнения', 'Вид маркировки', 'Вид маркируемой продукции ИС МП',\n",
        "       'Обувная продукция', 'Признак предмета расчета',\n",
        "       'Направление деятельности', 'Использовать партии',\n",
        "       'Обязательное заполнение партий', 'Нижняя граница остатков',\n",
        "       'Верхняя граница остатков']].copy(deep=True)\n",
        "#  'Ценовая группа', # в будущем может пригодиться\n",
        "SKUexport.rename(columns={\n",
        "                 'НАИМЕНОВАНИЕ_ДЛИННОЕ' : 'Наименование'\n",
        "                ,'АРТИКУЛ_ДЛИННЫЙ' : 'Артикул'\n",
        "                ,'SubGroupe' : 'Категория'\n",
        "                ,'Тип номенклатуры по умолчанию' : 'ТипНоменклатуры'\n",
        "                ,'Способ списания' : 'МетодОценки'\n",
        "                ,'КодЕд' : 'Единица измерения'\n",
        "                ,'Обязательное заполнение партий' : 'ПроверятьЗаполнениеПартий'\n",
        "                ,'Вид маркируемой продукции ИС МП' : 'ВидПродукцииИС'\n",
        "                ,'Поставщик_Имя' : 'Поставщик'\n",
        "                        },inplace=True)\n",
        "SKUexport = SKUexport.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "pWUxejtPp0C4"
      },
      "outputs": [],
      "source": [
        "# Фрейм SKUexportAll (вся номенклатура из исходника)\n",
        "# Фрейм SKUexportNew (номенклатуры нет в 1с, но есть в исходнике)\n",
        "# Фрейм SKUexportOld (номенклатуры нет в исходнике, но есть в 1с)\n",
        "SKUexportAll = SKUexport.copy(deep=True)\n",
        "SKUexportAll.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        "\n",
        "SKUexportNew = SKUexport.copy(deep=True)\n",
        "SKUexportNew = SKUexportNew\\\n",
        "  .merge(from1c[['Код','Номенклатура']], on='Номенклатура', how='left')\n",
        "SKUexportNew = SKUexportNew[SKUexportNew['Код'].isna()] \n",
        "SKUexportNew.drop(columns=['Код'], inplace= True) # все равно пустая\n",
        "# тут NaN по коду это строки с новыми карточками, вытащим их как раз\n",
        "SKUexportNew.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        " \n",
        "SKUexportOld = SKUexport.copy(deep=True)\n",
        "SKUexportOld = SKUexport\\\n",
        "  .merge(from1c[['Код','Номенклатура']], on='Номенклатура', how='right')\\\n",
        "  .merge(BarNoDup[['SubGroupe','Номенклатура']], on='Номенклатура',how='left')\\\n",
        "\n",
        "SKUexportOld['ТОВАР'] = SKUexportOld['Код'].str[3:].astype('Int64') #код домино\n",
        "SKUexportOld = SKUexportOld[SKUexportOld['SubGroupe'].notna()]#оставить тестовый\n",
        "SKUexportOld = SKUexportOld[SKUexportOld['Наименование'].isna()]\n",
        "SKUexportOld = SKUexportOld[['Номенклатура','SubGroupe']]\n",
        "SKUexportOld = SKUexportOld\\\n",
        "    .merge(from1c[['Недействительна','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(from1c[['Категория','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(from1c[['Наименование','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\n",
        "\n",
        "SKUexportOld.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        "# Все коды из 1с, тут NaN по наименованию это то, что в исходнике не нашлось\n",
        "# выдает просто список кодов. Не убить тестовые раз. Можно достать из\n",
        "# баркодов новую группу и заменить, не удалять их \n",
        "# merge изначально не работал из-за разного столбца \"номенклатура\"\n",
        "# из домино и из 1с, кодировка?\n",
        "\n",
        "# Переименовать Номенклатуру в Код для 1с пришлось после, костыль"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "yI7ATIjAN0Lw"
      },
      "outputs": [],
      "source": [
        "# Фрейм BarcodeExportNew только штрихкода к новым карточкам\n",
        "# Проверять наличие уже их в 1с тогда надо бы сразу\n",
        "BarcodeExportNew = df1[['Номенклатура', 'Штрихкод']].copy(deep=True)\n",
        "BarcodeExportNew.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        "BarcodeExportNew = BarcodeExportNew.merge(SKUexportNew['Код']\\\n",
        "                                          , how='inner')\n",
        "BarcodeExportNew.rename(columns={'Код': 'Номенклатура'}, inplace=True)\n",
        "# Оставить только совпавшие SKUexportNew строки, новый товар\n",
        "# Нюансик, строки без штрихкода дропаются тоже how='inner'                                                                   \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QNKY7DNJkXlm"
      },
      "outputs": [],
      "source": [
        "# Фрейм PriceExport под штатную загрузку розничной цены и менеджера\n",
        "PriceExport = skuDf[['Штрихкод', 'ЦЕНА(ПР)','Мен1С']].copy(deep=True)\n",
        "PriceExport['Штрихкод'] =  PriceExport['Штрихкод'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм партии номенклатуры\n",
        "batchExport = batch[['Номенклатура', 'Партия',\n",
        "                     'ПОСТАВЩИК', 'ДОГ']].copy(deep=True)\n",
        "batchExport = batchExport\\\n",
        "    .merge(batch_statusDf[['СтатусОплаты1С','ДОГ']], on='ДОГ', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Статус_НДС','ПОСТАВЩИК']]\\\n",
        "                        , on='ПОСТАВЩИК', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Имя','ПОСТАВЩИК']]\\\n",
        "                        , on='ПОСТАВЩИК', how='left')\n",
        "batchExport['Наименование'] = batchExport['Партия'].astype(str)\n",
        "batchExport['Статус'] = batchExport['СтатусОплаты1С']\n",
        "batchExport['Владелец партии'] =batchExport['Поставщик_Имя']\n",
        "batchExport['Налогообложение'] =batchExport['Поставщик_Статус_НДС']\n",
        "\n",
        "batchExport = batchExport[['Номенклатура','Наименование','Статус', \n",
        "                            'Владелец партии','Налогообложение',]]"
      ],
      "metadata": {
        "id": "g7BCmEHs7a18"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм bdfExport остатки по партиям\n",
        "# Комиссия отдельно сделать\n",
        "# Ошибка если единицы из домина не по списку приходят, case censitive в.т.ч\n",
        "# Лечить в Домине не дожидаясь перитонита\n",
        "# в Домине не лечится, возьмем из базовых из исходника\n",
        "# Допилить проверку ошибок\n",
        "bdf = batch.copy(deep=True)\n",
        "bdf['Партия'] = bdf['Партия'].astype(str)\n",
        "\n",
        "input_rows = bdf.shape[0]\n",
        "input_qtt = bdf['ИСХ_КОЛИЧ'].sum().round(2)\n",
        "input_sum = bdf['СебестРуб.3'].sum().round(2)\n",
        "\n",
        "bdf = bdf\\\n",
        "    .merge(df2[['ЕИ','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['Штрихкод','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['SubGroupe','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Имя','ПОСТАВЩИК']]\\\n",
        "           , on='ПОСТАВЩИК', how='left')\\\n",
        "    .merge(batch_statusDf[['ВидОперации','ДОГ']]\\\n",
        "           , on='ДОГ', how='left')\\\n",
        "    .merge(unitsDf[['КодЕд','ЕИ']], on='ЕИ', how='left')\\\n",
        "    .merge(unitsDf[['1сКрЕИ','ЕИ']], on='ЕИ', how='left')   \n",
        "\n",
        "bdf = bdf.sort_values(by=['ВидОперации'])\n",
        "bdf['Контрагент'] = bdf['Поставщик_Имя']\n",
        "bdf['Единица измерения'] = bdf['1сКрЕИ']\n",
        "\n",
        "bdf['Договор'] = 'Основной договор'   \n",
        "bdf[['1эт остаток', '2эт остаток','скл1 остаток', 'б/н остаток',\n",
        "           'брак остаток', 'ИСХ_КОЛИЧ','СебестРуб.3']] = bdf[['1эт остаток', \n",
        "           '2эт остаток','скл1 остаток', 'б/н остаток',\n",
        "           'брак остаток', 'ИСХ_КОЛИЧ','СебестРуб.3']].fillna(0)    \n",
        "\n",
        "bdf['хозу остаток'] =  bdf['ИСХ_КОЛИЧ'] - bdf['1эт остаток']\\\n",
        "                     - bdf['2эт остаток'] - bdf['скл1 остаток']\\\n",
        "                     - bdf['б/н остаток'] - bdf['брак остаток']  \n",
        "bdf['Себестоимость'] = bdf['СебестРуб.3'] / bdf['ИСХ_КОЛИЧ']\n",
        "\n",
        "serv_rows = bdf[bdf['ГРУППА'] == '!!УСЛУГИ'].index.value_counts().sum()\n",
        "serv_qtt = bdf[bdf['ГРУППА'] == '!!УСЛУГИ']['ИСХ_КОЛИЧ'].sum().round(2) \n",
        "serv_sum = bdf[bdf['ГРУППА'] == '!!УСЛУГИ']['СебестРуб.3'].sum().round(2)\n",
        "# У услуг нет остатка\n",
        "\n",
        "bdf.drop(bdf[(bdf['ГРУППА'] == '!!УСЛУГИ')].index, inplace=True)\n",
        "\n",
        "# тут мы сцепляем остатки по подразделениям в одну таблицу\n",
        "batchSum = pd.DataFrame()\n",
        "storage_domino = warehousesDf['Отдел'].values\n",
        "storage_1c = warehousesDf['СтруктурнаяЕдиница'].values\n",
        "i = 0\n",
        "z = 0\n",
        "for x in storage_domino:\n",
        "    # print('step ', i) # отладочное\n",
        "    # print('x=',x)\n",
        "    # print(storage_1c[i])\n",
        "    bdfTmp = bdf[bdf[x] != 0].copy()\n",
        "    bdfTmp['СтруктурнаяЕдиница'] = storage_1c[i] #Склад 1c\n",
        "    bdfTmp['Количество'] = bdfTmp[x]\n",
        "    bdfTmp['Сумма'] = bdfTmp['Количество'] * bdfTmp['Себестоимость']\n",
        "    z = z + bdfTmp.shape[0]\n",
        "    # print(bdfTmp.shape[0], 'rows')\n",
        "    # print(z, 'rowsSum')\n",
        "    batchSum = pd.concat([batchSum, bdfTmp], ignore_index= True)\n",
        "    i = i + 1\n",
        "##############################################################################\n",
        "bdfExportAll = batchSum[['Номенклатура', 'Партия', 'Количество',\n",
        "                      'Единица измерения', 'Сумма',\n",
        "                      'СтруктурнаяЕдиница', 'Контрагент',  # 'Себестоимость',\n",
        "                      'ВидОперации', 'Договор'              \n",
        "                     ]].copy()\n",
        "\n",
        "output_rows = batchSum.shape[0]\n",
        "output_qtt = batchSum['Количество'].sum().round(2)\n",
        "output_sum = batchSum['Сумма'].sum().round(2)\n",
        "# Загрузить минусовые комиссия как плюсы  ####################################\n",
        "bdfExportNegativeTitleСommission = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.notna() & Количество < 0', engine='python')\n",
        "bdfExportNegativeTitleСommission['Количество'] = \\\n",
        "                         bdfExportNegativeTitleСommission['Количество'].abs()\n",
        "bdfExportNegativeTitleСommission['Сумма'] = \\\n",
        "                         bdfExportNegativeTitleСommission['Сумма'].abs()\n",
        "# Загрузить минусовые свои как плюсы  ########################################\n",
        "bdfExportNegativeTitlePurchased = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.isna() & Количество < 0', engine='python')\n",
        "bdfExportNegativeTitlePurchased['Количество'] = \\\n",
        "                         bdfExportNegativeTitlePurchased['Количество'].abs()\n",
        "bdfExportNegativeTitlePurchased['Сумма'] = \\\n",
        "                         bdfExportNegativeTitlePurchased['Сумма'].abs()\n",
        "# Для списать все в двойном размере, подразделение????####################### \n",
        "bdfExportNegativeTitleAllx2 = bdfExportAll.copy(deep=True).query\\\n",
        "                                        ('Количество < 0', engine='python')\n",
        "bdfExportNegativeTitleAllx2['Количество'] = \\\n",
        "                         bdfExportNegativeTitleAllx2['Количество'].abs() * 2\n",
        "bdfExportNegativeTitleAllx2['Сумма'] = \\\n",
        "                         bdfExportNegativeTitleAllx2['Сумма'].abs() * 2\n",
        "# Плюсовые комиссия только положительные  ###################################\n",
        "bdfExportPositiveTitleСommission = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.notna() & Количество > 0', engine='python')\n",
        "# Плюсовые свои только положительные   ######################################\n",
        "bdfExportPositiveTitlePurchased = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.isna() & Количество > 0', engine='python')\n",
        "# Плюсовые комиссия все подряд по модулю  ###################################\n",
        "bdfExportPositiveTitleСommissionAll = bdfExportAll.copy(deep=True).query\\\n",
        "                                   ('ВидОперации.notna()', engine='python')\n",
        "bdfExportPositiveTitleСommissionAll['Количество'] = \\\n",
        "                         bdfExportPositiveTitleСommissionAll['Количество'].abs()\n",
        "bdfExportPositiveTitleСommissionAll['Сумма'] = \\\n",
        "                         bdfExportPositiveTitleСommissionAll['Сумма'].abs()\n",
        "# Плюсовые свои все подряд по модулю      ###################################\n",
        "bdfExportPositiveTitlePurchasedAll = bdfExportAll.copy(deep=True).query\\\n",
        "                                   ('ВидОперации.isna()', engine='python')\n",
        "bdfExportPositiveTitlePurchasedAll['Количество'] = \\\n",
        "                         bdfExportPositiveTitlePurchasedAll['Количество'].abs()\n",
        "bdfExportPositiveTitlePurchasedAll['Сумма'] = \\\n",
        "                         bdfExportPositiveTitlePurchasedAll['Сумма'].abs()\n",
        "\n",
        "##############################################################################\n",
        "output1_rows = bdfExportNegativeTitleСommission.shape[0]\n",
        "output1_qtt = bdfExportNegativeTitleСommission['Количество'].sum().round(2)\n",
        "output1_sum = bdfExportNegativeTitleСommission['Сумма'].sum().round(2)\n",
        "\n",
        "output2_rows = bdfExportNegativeTitlePurchased.shape[0]\n",
        "output2_qtt = bdfExportNegativeTitlePurchased['Количество'].sum().round(2)\n",
        "output2_sum = bdfExportNegativeTitlePurchased['Сумма'].sum().round(2)\n",
        "\n",
        "output3_rows = bdfExportPositiveTitleСommission.shape[0]\n",
        "output3_qtt = bdfExportPositiveTitleСommission['Количество'].sum().round(2)\n",
        "output3_sum = bdfExportPositiveTitleСommission['Сумма'].sum().round(2)\n",
        "\n",
        "output4_rows = bdfExportPositiveTitlePurchased.shape[0]\n",
        "output4_qtt = bdfExportPositiveTitlePurchased['Количество'].sum().round(2)\n",
        "output4_sum = bdfExportPositiveTitlePurchased['Сумма'].sum().round(2)\n",
        "\n",
        "check = pd.DataFrame({'Rows': [input_rows, serv_rows, output_rows,\n",
        "                      output1_rows, output2_rows, output3_rows, output4_rows],\n",
        "                     'quantity': [input_qtt, serv_qtt, output_qtt,\n",
        "                     output1_qtt, output2_qtt, output3_qtt, output4_qtt],\n",
        "                     'sum': [input_sum, serv_sum, output_sum,\n",
        "                            output1_sum, output2_sum, output3_sum, output4_sum]\n",
        "                      },index=['Input', 'Service', 'Output',\n",
        "                         '-com', '-our', '+com', '+our',       ])\n",
        "\n",
        "check.loc['Check (rows is OK)'] = check.loc['Output'] -\\\n",
        "                              (check.loc['Input'] - check.loc['Service']) \n",
        "check.loc['Check (+-= OK)'] =-check.loc['-com'] - check.loc['-our']\\\n",
        "                             +check.loc['+com'] + check.loc['+our']\\\n",
        "                             -check.loc['Output']\n",
        "                                                                    "
      ],
      "metadata": {
        "id": "BVLDGODBtdlB"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP3UKKl1awHp"
      },
      "source": [
        "## Блок проверки констситентности\n",
        "## Если проверка не прошла, вылезет ошибка, блок записи не запустится\n",
        "Список возможных глюков на входе:\n",
        "*   Единицы измерения не из списка, хранятся в партиях, нужно базовые в партии перезаписывать чтобы накатился фикс. А они не записываются, база не дает, я в восхищении!\n",
        "*   Непечатываемые символы из Домино (Code31) в частности Ищется поиском в экселе =НАЙТИ(СИМВОЛ(33);A1)\n",
        "   \n",
        "\n",
        "Придумать как штрихкоды в 1с чистить те, которые поменялись, чтобы всю пачку не грузить и дублей не было\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sfBTvB3pb22-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2508526-7b18-4f88-bc56-59e16ab8c0a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variable                              Type         Data/Info\n",
            "------------------------------------------------------------\n",
            "BarNoDup                              DataFrame             ТОВАР Номенклату<...>167913 rows x 15 columns]\n",
            "BarcodeExport                         DataFrame          Номенклатура       <...>n[41455 rows x 2 columns]\n",
            "BarcodeExportNew                      DataFrame        Номенклатура       Шт<...>n\\n[125 rows x 2 columns]\n",
            "PriceExport                           DataFrame                Штрихкод  ЦЕН<...>n[33840 rows x 3 columns]\n",
            "SKUexport                             DataFrame          Номенклатура       <...>[33840 rows x 22 columns]\n",
            "SKUexportAll                          DataFrame                   Код       <...>[33840 rows x 22 columns]\n",
            "SKUexportNew                          DataFrame                   Код       <...>\\n[122 rows x 22 columns]\n",
            "SKUexportOld                          DataFrame                   Код       <...>\\n[2506 rows x 2 columns]\n",
            "batch                                 DataFrame            ТОВАР      Партия<...>[28623 rows x 35 columns]\n",
            "batchExport                           DataFrame          Номенклатура Наимен<...>n[28623 rows x 5 columns]\n",
            "batchSum                              DataFrame            ТОВАР      Партия<...>[29164 rows x 50 columns]\n",
            "batch_statusDf                        DataFrame       ДОГ          СтатусОпл<...>  Да  Прием на комиссию  \n",
            "bdf                                   DataFrame            ТОВАР      Партия<...>[28619 rows x 47 columns]\n",
            "bdfExportAll                          DataFrame          Номенклатура      П<...>n[29164 rows x 9 columns]\n",
            "bdfExportNegativeTitleAllx2           DataFrame          Номенклатура      П<...>n\\n[382 rows x 9 columns]\n",
            "bdfExportNegativeTitlePurchased       DataFrame          Номенклатура      П<...>n\\n[379 rows x 9 columns]\n",
            "bdfExportNegativeTitleСommission      DataFrame         Номенклатура      Па<...>n2471  Основной договор  \n",
            "bdfExportPositiveTitlePurchased       DataFrame          Номенклатура      П<...>n[28376 rows x 9 columns]\n",
            "bdfExportPositiveTitlePurchasedAll    DataFrame          Номенклатура      П<...>n[28755 rows x 9 columns]\n",
            "bdfExportPositiveTitleСommission      DataFrame         Номенклатура      Па<...>n\\n[406 rows x 9 columns]\n",
            "bdfExportPositiveTitleСommissionAll   DataFrame         Номенклатура      Па<...>n\\n[409 rows x 9 columns]\n",
            "bdfTmp                                DataFrame    Empty DataFrame\\nColumns:<...>\\n\\n[0 rows x 50 columns]\n",
            "catalog1c                             DataFrame                             <...>\\n[927 rows x 17 columns]\n",
            "check                                 DataFrame                           Ro<...>0       0.00         0.00\n",
            "df1                                   DataFrame             ТОВАР Номенклату<...>201599 rows x 15 columns]\n",
            "df2                                   DataFrame            ТОВАР Номенклатур<...>[33840 rows x 35 columns]\n",
            "from1c                                DataFrame           Код Домино        <...>[36235 rows x 36 columns]\n",
            "managersDf                            DataFrame        МЕНЕДЖЕР    Мен1С\\n0 <...>ич\\n3   10.15 БХ  Фраймут\n",
            "skuDf                                 DataFrame            ТОВАР Номенклатур<...>[33840 rows x 63 columns]\n",
            "suppliersDf                           DataFrame              Поставщик_Имя  <...>\\n[132 rows x 14 columns]\n",
            "unitsDf                               DataFrame         ЕИ КодЕд  1сКрЕИ    <...>   Штука              PCE\n",
            "warehousesDf                          DataFrame                         Скла<...>'  \\n5    '1эт остаток'  \n",
            "--------------------------------------------------------------------------------\n",
            "OK Исходник на входе 33840 строк совпадает по длине     с итоговым 33840 строк\n",
            "OK 0 строк без поставщика\n",
            "OK 0 строк без единицы измерения\n",
            "На входе df2 исходник текущий строк: 33840\n",
            "Будет выгружен SKUexportAll строк: 33840\n",
            "Будет выгружен SKUexportNew строк: 122\n",
            "Будет выгружен SKUexportOld строк: 2506\n",
            "Будет выгружен BarcodeExport строк: 41455\n",
            "Будет выгружен BarcodeExportNew строк: 125\n",
            "Будет выгружен PriceExport строк: 33840\n",
            "--------------------------------------------------------------------------------\n",
            "Проверка выгрузки партий\n",
            "--------------------------------------------------------------------------------\n",
            "                       Rows   quantity          sum\n",
            "Input               28623.0  251904.23  28696366.95\n",
            "Service                 4.0   -1497.00      1485.02\n",
            "Output              29164.0  253401.23  28694881.93\n",
            "-com                    3.0       3.00      1000.96\n",
            "-our                  379.0    1351.59    118719.37\n",
            "+com                  406.0    1221.00    748612.96\n",
            "+our                28376.0  253534.82  28065989.30\n",
            "Check (rows is OK)    545.0       0.00         0.00\n",
            "Check (+-= OK)       -764.0       0.00         0.00\n",
            "--------------------------------------------------------------------------------\n",
            "Qtt is OK  0.0\n",
            "Sum is OK  0.0\n",
            "TotalQtt is OK  0.0\n",
            "TotalSum is OK  0.0\n"
          ]
        }
      ],
      "source": [
        "%whos DataFrame\n",
        "print('-'*80)\n",
        "inputLen, outputLen = len(df2), len(SKUexportAll)\n",
        "if inputLen == outputLen:\n",
        "    print(f'OK Исходник на входе {inputLen} строк совпадает по длине\\\n",
        "     с итоговым {outputLen} строк')\n",
        "else:\n",
        "    raise Exception(f'Количество строк на входе и выходе не совпадает на:\\\n",
        "     {inputLen - outputLen} строк')\n",
        "\n",
        "noSupplier = SKUexportAll['Поставщик'].isna().sum()   \n",
        "if noSupplier == 0:\n",
        "    print(f'OK {noSupplier} строк без поставщика')\n",
        "else:\n",
        "    raise Exception(f'{noSupplier} строк без поставщика')\n",
        "\n",
        "noUnit = SKUexportAll['Единица измерения'].isna().sum() \n",
        "if noUnit == 0:\n",
        "    print(f'OK {noUnit} строк без единицы измерения')\n",
        "else:\n",
        "    raise Exception(f'{noUnit} строк без единицы измерения')\n",
        "\n",
        "print ('На входе df2 исходник текущий строк:',df2.shape[0])\n",
        "print ('Будет выгружен SKUexportAll строк:',SKUexportAll.shape[0])\n",
        "print ('Будет выгружен SKUexportNew строк:',SKUexportNew.shape[0])\n",
        "print ('Будет выгружен SKUexportOld строк:',SKUexportOld.shape[0])\n",
        "print ('Будет выгружен BarcodeExport строк:',BarcodeExport.shape[0])\n",
        "print ('Будет выгружен BarcodeExportNew строк:',BarcodeExportNew.shape[0])\n",
        "print ('Будет выгружен PriceExport строк:',PriceExport.shape[0])\n",
        "print('-'*80)\n",
        "print ('Проверка выгрузки партий')\n",
        "print('-'*80)\n",
        "print(check)\n",
        "print('-'*80)\n",
        "CheckQtt = check['quantity'][-2]\n",
        "CheckSum = check['sum'][-2]\n",
        "TotalQtt = check['quantity'][-1]\n",
        "TotalSum = check['sum'][-1]\n",
        "TotalCheck = CheckQtt + CheckSum + TotalQtt + TotalSum\n",
        "if TotalCheck == 0:\n",
        "    print(f'Qtt is OK ', CheckQtt) #Строк больше на совпавшие по отделам запасы\n",
        "    print(f'Sum is OK ', CheckSum)\n",
        "    print(f'TotalQtt is OK ', TotalQtt)#Строк меньше на количество отрицательных\n",
        "    print(f'TotalSum is OK ', TotalSum)#Это только в чеке, так их столько же\n",
        "else:\n",
        "    raise Exception(f'{CheckQtt},{CheckQtt},{TotalQtt},{TotalSum} не совпали строки по партиям')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_iTMisY3oXq"
      },
      "source": [
        "##Блок записи в файлы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "XfNisczxGgE-"
      },
      "outputs": [],
      "source": [
        "# engine менять обязательно, иначе не сохраняет эксельки\n",
        "# ВЫГРУЖАЕТ фрейм BarcodeExport в BarcodesAll.xlsx  \n",
        "file_name = 'BarcodesAll'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "BarcodeExport.to_excel(file_name, index=False, header=True\\\n",
        "                       , freeze_panes=(1,1), engine='xlsxwriter') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_gExEQ21oXeF"
      },
      "outputs": [],
      "source": [
        "# ВЫГРУЖАЕТ фрейм BarcodeExportNew в BarcodesNew.xlsx  \n",
        "file_name = 'BarcodesNew'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "BarcodeExportNew.to_excel(file_name, index=False, header=True\\\n",
        "                       , freeze_panes=(1,1), engine='xlsxwriter') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YvVjCpiOli1P"
      },
      "outputs": [],
      "source": [
        "# ВЫГРУЖАЕТ фрейм PriceExport в Price.xlsx  \n",
        "file_name = 'Price'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "PriceExport.to_excel(file_name, index=False, header=True\\\n",
        "                     , freeze_panes=(1,1), engine='xlsxwriter') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "i6siTlCh7hZx"
      },
      "outputs": [],
      "source": [
        "# Выгружает Фрейм SKUexportAll в SkuAll.xlsx \n",
        "# Справочник всех товаров из исходника для первичного импорта в 1С\n",
        "file_name = 'SkuAll'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SKUexportAll.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "ycFrP3N239m8"
      },
      "outputs": [],
      "source": [
        "# Выгружает Фрейм SKUexportNew в SkuNew.xlsx \n",
        "# Справочник новых товаров из исходника для импорта в 1С\n",
        "file_name = 'SkuNew'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SKUexportNew.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "0WlJktT1D_pi"
      },
      "outputs": [],
      "source": [
        "# Выгружает Фрейм SKUexportOld в SkuOld.xlsx \n",
        "# Справочник новых товаров из исходника для импорта в 1С\n",
        "file_name = 'SkuOld'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SKUexportOld.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм batchExport в batchExport.xlsx\n",
        "# Справочник партий, xlsxwriter партии жрет как числа, лечится .astype(str)\n",
        "file_name = 'batchExport'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "batchExport.to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "DwRV5BidGHpO"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает # Фреймы bdfExport в Export.xlsx\n",
        "# остатки по партиям\n",
        "dfList = ['bdfExportAll', 'bdfExportNegativeTitlePurchased',\n",
        "   'bdfExportNegativeTitleСommission', 'bdfExportPositiveTitlePurchased',\n",
        "   'bdfExportPositiveTitleСommission', 'bdfExportNegativeTitleAllx2',\n",
        "   'bdfExportPositiveTitleСommissionAll', 'bdfExportPositiveTitlePurchasedAll']\n",
        "fileList =  [s.replace('bdfExport','Export') for s in dfList]\n",
        "\n",
        "i = 0\n",
        "for x in dfList:\n",
        "    file_name = fileList[i]\n",
        "    file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "    locals()[x].to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "hyKdWT4Fymg2"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwgHaoJxgBCM"
      },
      "source": [
        " Шпаргалка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "i5M9YghuvLz8",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#@title Текст заголовка по умолчанию\n",
        "#ШПАРГАЛКА\n",
        "\n",
        "# df\n",
        "# df.columns\n",
        "# df.head(5)\n",
        "# df.tail(5)\n",
        "# df.info()\n",
        "# df.dtypes\n",
        "# df['ТОВАР'] #одна колонка\n",
        "# df[['ТОВАР','1эт остаток','2эт остаток']] #3 колонки\n",
        "# df['ТОВАР'].hist #гистограмма\n",
        "# df.describe()\n",
        "# df['SubGroupe'].value_counts() # подсчет уникальных значений\n",
        "# df['SubGroupe'].value_counts(dropna=False) #включая пустые\n",
        "# q = df['Продано'].quantile(0.25)\n",
        "# df[df['Продано'] < q]\n",
        "\n",
        "# df = skuDf[skuDf['Счет учета затрат'].isna()] \n",
        "# df\n",
        "# df['SubGroupe'].value_counts(dropna=False)\n",
        "\n",
        "# df = skuDf[skuDf['Вид маркируемой продукции ИС МП'].notna()] \n",
        "# df\n",
        "# df['SubGroupe'].value_counts(dropna=False)\n",
        "\n",
        "# skuDf.groupby('В группе',dropna=False)['РозницаРуб'].agg(['count','sum','mean']).sort_values(by='sum', ascending=False)\n",
        "\n",
        "# BarcodeExport[:10].to_csv #первые 10\n",
        "# BarcodeExport['ТОВАР'] = BarcodeExport['ТОВАР'].astype('Int64') \n",
        "# batch['ТОВАР'] = batch['Партия'].astype('Float64').astype('Int64') #перевод партии сначала из текста с точкой в флоат, потом в инт\n",
        "# df[df2['1эт остаток'].notna()]\n",
        "# df[df[\"col\"]. str.contains (\" this string \")] поиск в базе 'unicode_escape'\n",
        "# BarcodeExport['Номенклатура'] = 'ДМ-' + BarcodeExport['ТОВАР'].apply('{:0>8} '. format).astype (str) #приклеить префикс\n",
        "# bdf.groupby('ГРУППА',dropna=False)['ИСХ_КОЛИЧ'].agg(['count','sum']).sort_values(by='ГРУППА', ascending=True)\n",
        "# Таблица не мерджится тк в 1с всосали все подгруппы в верхнем регистре\n",
        "# df_address['country_lower'] = df_address['Country'].str.lower()\n",
        "#Save\n",
        "#file_name = '/content/drive/MyDrive/Colab Notebooks/Output/BarcodeExport_{}.csv'.format(datetime.now(pytz.timezone('Europe/Moscow')).strftime(\"%Y_%b_%d %H.%M.%S\"))\n",
        "#BarcodeExport.to_csv(file_name, sep=\";\", index=False, header=True, encoding='Windows-1251') \n",
        "# ??pd.DataFrame.to_excel\n",
        "# find = df2[df2['НАИМЕНОВАНИЕ'].str.contains('| '.join('unicode_escape'))]\n",
        "# find = skuDf[skuDf['НАИМЕНОВАНИЕ'].str.contains('САМОРЕЗ')]\n",
        "# ??pd.DataFrame.to_excel\n",
        "# df1 = df1.replace('unicode_escape',' ', regex=True) # В Теории это лечит непечатные символы, ток непонятно, работает ли. Не работает\n",
        "# !pip install xlsxwriter #for xlsxwriter as engine\n",
        "# print ('Я дошёл до конца и выполнился')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KOVCr5p7q42XXkXEguS84fU3KY1Taj5v",
      "authorship_tag": "ABX9TyNWmMd/cG+lG8Elep6WjJBI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}