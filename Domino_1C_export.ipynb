{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlexandrPinevich/Domino_to_1c_export/blob/main/Domino_1C_export.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgesjLMBFOou"
      },
      "source": [
        "## Эта штука должна парсить csv и исходники и рожать из них данные на вход в 1С для ввода начальных остатков. Файлы берутся из гугл диска. Для целей консистентности данных сильно желательно все файлы выгружать из Домина одним днем и одним пакетом"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "w--yulQ0uOwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6785669b-4ebe-4c49-8290-bf3dfa049b25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.9/dist-packages (3.0.9)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd            #БЕЗ ЭТОГО РАБОТАТЬ НЕ БУДЕТ!!!\n",
        "import numpy as np\n",
        "from datetime import datetime  #НАДО ЗАПУСКАТЬ ПЕРЕД ОБРАБОТКОЙ\n",
        "import pytz                    #ВООБЩЕ ВСЕ ПО ОЧЕРЕДИ НАДО ЗАПУСКАТЬ\n",
        "!pip install xlsxwriter        #ИНАЧЕ ЭКСЕЛЬ НЕ ПИШЕТСЯ ИЗ-ЗА КОДИРОВКИ"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пути\n",
        "input_path = '/content/drive/MyDrive/Colab Notebooks/Input/'\n",
        "output_path = '/content/drive/MyDrive/Colab Notebooks/Output/'\n",
        "time_now = '_' + (datetime.now(pytz.timezone('Europe/Moscow'))\\\n",
        "          .strftime(\"%Y_%b_%d %H.%M.%S\"))\n",
        "to_xlsx = '.xlsx'\n",
        "to_csv = '.csv'"
      ],
      "metadata": {
        "id": "L7ISX1nV_yPn"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CD304lqmzt4"
      },
      "source": [
        "## Блок считывания файлов. Папка Input\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "sb8LITeDmi0f"
      },
      "outputs": [],
      "source": [
        "# Это читает ИСХОДНИК текущий партии\n",
        "# предобработанный, но без ручной колонки партий\n",
        "file_name = '!!!!Исходник текущий партии.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "batch=pd.read_excel(file_name,header = 4, skipfooter = 1, keep_default_na=True\\\n",
        "                    , dtype={'ТОВАР': object}, sheet_name='gr_post')\n",
        "batch.rename(columns={'ТОВАР': 'Партия'}, inplace=True)\n",
        "batch.rename(columns={'ЕИ': 'ЕИпартии'}, inplace=True)\n",
        "batch.insert(0,'ТОВАР','')\n",
        "batch['ТОВАР'] = batch['Партия'].astype('Float64').astype('Int64')\n",
        "batch.insert(2,'Номенклатура','')\n",
        "batch['Номенклатура'] = 'ДМ-' + batch['ТОВАР'].apply('{:0>8}'.format)\\\n",
        "                                                             .astype(str)\n",
        "batch.dropna(subset=['ИСХ_КОЛИЧ'], inplace = True)\n",
        "# Дропает строки без остатка насовсем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "id": "Fbz9TbYjM2bN"
      },
      "outputs": [],
      "source": [
        "# Это читает ИСХОДНИК текущий уже экселем предобработанный\n",
        "file_name = '!!!!Исходник текущий.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "df2=pd.read_excel(file_name, header = 4, skipfooter = 1, keep_default_na=True\\\n",
        "                  , sheet_name='gr_post')\n",
        "df2.insert(1,'Номенклатура','')\n",
        "df2['Номенклатура'] = 'ДМ-' + df2['ТОВАР'].apply('{:0>8}'.format).astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "lfXKsFfbTQVy"
      },
      "outputs": [],
      "source": [
        "# Это читает файл ###Справочники\n",
        "file_name = '###Справочники.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "unitsDf=pd.read_excel(file_name, sheet_name='units', keep_default_na=True\\\n",
        "                          , dtype={'КодЕд': object})\n",
        "managersDf=pd.read_excel(file_name, sheet_name='managers', keep_default_na=True)\n",
        "warehousesDf=pd.read_excel(file_name, sheet_name='warehouses'\\\n",
        "                          , keep_default_na=True)\n",
        "batch_statusDf=pd.read_excel(file_name, sheet_name='batch_status'\\\n",
        "                          , keep_default_na=True)\n",
        "suppliersDf=pd.read_excel(file_name, sheet_name='suppliers'\\\n",
        "                          , keep_default_na=True\\\n",
        "                          , dtype={'Поставщик_Номер_в_Домино': object})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "UfUe6_j44Oxr"
      },
      "outputs": [],
      "source": [
        "# Это читает BARCODES.CSV сырой, как выпал из отчета Домино\n",
        "# keep_default_na = 1/0 ПЕРЕКЛЮЧАТЕЛЬ ВЫВОДА NaN\n",
        "file_name = 'barcodes.csv'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "header_list = ['ТОВАР','Штрихкод','ТОВАР2','НАИМЕНОВАНИЕ_ДЛИННОЕ',\n",
        "          'АРТИКУЛ_ДЛИННЫЙ','GrNum','Group','SrgNum','SubGroupeAsIs',\n",
        "          'supplierCode','supplier','countryCode','country']\n",
        "\n",
        "df1 = pd.read_csv(file_name, delimiter = ';', header=None, names = header_list,\n",
        "            encoding='Windows-1251')\n",
        "#,header=None, header=None, iterator = False, index_col = False, \n",
        "# , engine='c''pyarrow', nrows=100 keep_default_na=True,, low_memory=False\n",
        "\n",
        "df1.insert(1,'Номенклатура','')\n",
        "df1['Номенклатура'] = 'ДМ-' + df1['ТОВАР'].apply('{:0>8}'.format).astype(str)\n",
        "df1['SubGroupe'] = df1['SubGroupeAsIs'].str.upper()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "ZANy-leO1ARe"
      },
      "outputs": [],
      "source": [
        "# Это читает SKU из 1С нужно чтобы только новые карточки можно было добавить\n",
        "# или страрые удалить\n",
        "file_name = 'SKU from 1C.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "from1c = pd.read_excel(file_name, sheet_name='TDSheet')\n",
        "from1c['Номенклатура'] ='ДМ-' + from1c['Код Домино'].apply('{:0>8}'.format)\\\n",
        "    .astype(str)\n",
        "from1c['Менеджер'] = from1c['Ссылка.Менеджер (\"Общие\")']\n",
        "from1c['Мен1С'] = from1c['Ссылка.Менеджер (\"Общие\")']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "kl0yPbCByiWP"
      },
      "outputs": [],
      "source": [
        "# Это читает Категории из 1С \n",
        "file_name = 'Категории из 1С.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "catalog1c=pd.read_excel(file_name,sheet_name='TDSheet')\n",
        "catalog1c['SubGroupe'] = catalog1c['Подгруппа']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Это читает Штрихкоды из 1С \n",
        "file_name = 'Штрихкода из 1с.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "BarFrom1c=pd.read_excel(file_name,sheet_name='TDSheet')\n",
        "BarFrom1c['Номенклатура'] = BarFrom1c['Номенклатура.Код']"
      ],
      "metadata": {
        "id": "3bs0I4LoMgWa"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Это читает Цены из 1С \n",
        "file_name = 'Цены розница из 1с.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "PriceFrom1c=pd.read_excel(file_name,sheet_name='TDSheet')\n",
        "PriceFrom1c.rename(columns={'Номенклатура': 'Наименование'\n",
        "                          ,'Код' : 'Номенклатура'\n",
        "                          ,'Ед.' : 'Единица измерения'                            \n",
        "                          }, inplace=True)"
      ],
      "metadata": {
        "id": "1VKrCtNTupse"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Это читает Партии из 1С\n",
        "file_name = 'Партии из 1с.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "batch_from1c_df = pd.read_excel(file_name,sheet_name='TDSheet',\\\n",
        "                               dtype={'Ссылка': object})\n",
        "batch_from1c_df['Наименование']  = batch_from1c_df['Ссылка']\n",
        "batch_from1c_df['Партия']  = batch_from1c_df['Ссылка']\n",
        "batch_from1c_df['Номенклатура']  = batch_from1c_df['Номенклатура.Код']"
      ],
      "metadata": {
        "id": "wCmpr_Y1JMYo"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Это читает 700ку\n",
        "# Пофиксить возврат ДЖБА, косяки с партиями МК, строки портит обоим\n",
        "file_name = 'Семисотка текущая.xlsx'\n",
        "file_name = ''.join((input_path, file_name))\n",
        "MoneyInputDf=pd.read_excel(file_name, header = 5, skipfooter = 2,\n",
        "                        usecols = ('A:L'), keep_default_na=True, sheet_name=0)"
      ],
      "metadata": {
        "id": "_PLl-hdQig3G"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2nBWD1jN3fwj"
      },
      "source": [
        "## Блок обработки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "-1hcfBB_AzDV"
      },
      "outputs": [],
      "source": [
        "# Фрейм BarNoDup Убирает дубликаты строк из df1 - BARCODES.CSV по коду,\n",
        "# нужно для корректного джойна с исходником\n",
        "BarNoDup = df1.copy(deep=True).drop_duplicates(subset=['ТОВАР'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Bup5qnn_sYSF"
      },
      "outputs": [],
      "source": [
        "# Фрейм BarcodeExport Забираем из таблицы с штрихкодами 2 колонки\n",
        "# в новый датафрейм BarcodeExport для последующей выгрузки\n",
        "BarcodeExport = df1[['Номенклатура', 'Штрихкод']].copy(deep=True)\n",
        "BarcodeExport = BarcodeExport.merge(df2['Номенклатура'], how='inner')\n",
        "# Оставить только совпавшие c исходником строки,\n",
        "# Нюансик, строки без штрихкода дропаются тоже how='inner'                                                                   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "-5KMhQfhl7pH"
      },
      "outputs": [],
      "source": [
        "# Фрейм skuDf копирует исходник чтобы избежать возможного конфликта\n",
        "# последовательности загрузки, в нем же добавляем колонки, кот. нужны на импорт\n",
        "# а не надо здесь ешё наличие штрихкода в домине проверить к этим карточкам?\n",
        "skuDf = df2.copy(deep=True)\n",
        "skuDf = skuDf\\\n",
        "    .merge(BarNoDup[['НАИМЕНОВАНИЕ_ДЛИННОЕ','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['АРТИКУЛ_ДЛИННЫЙ','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['SubGroupe','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(unitsDf[['КодЕд','ЕИ']], on='ЕИ', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Имя','ПОСТАВЩИК']]\\\n",
        "           , on='ПОСТАВЩИК', how='left')\\\n",
        "    .merge(managersDf[['Мен1С','МЕНЕДЖЕР']], on='МЕНЕДЖЕР', how='left')\\\n",
        "    .merge(catalog1c, left_on='SubGroupe', right_on='SubGroupe', how='left')\n",
        "\n",
        "skuDf.insert(36,'Наименование полное','')\n",
        "skuDf['Наименование полное'] = skuDf['НАИМЕНОВАНИЕ_ДЛИННОЕ']\n",
        "skuDf['Направление деятельности'] = 'Основное направление'\n",
        "skuDf['Использовать партии'] = 'Да'\n",
        "skuDf['Обязательное заполнение партий'] = 'Да'\n",
        "skuDf['Нижняя граница остатков'] = skuDf['МИН'].abs()\n",
        "skuDf['Верхняя граница остатков'] = skuDf['УП'].abs()\n",
        "skuDf['Цена'] = skuDf['ЦЕНА(ПР)']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "J2-AiAxJuLnf"
      },
      "outputs": [],
      "source": [
        "# Фрейм SKUexport Забираем из skuDf нужные колонки и переименовываем \n",
        "# для последующей выгрузки в файл\n",
        "SKUexport =skuDf[['Номенклатура', 'НАИМЕНОВАНИЕ_ДЛИННОЕ',\n",
        "       'Наименование полное','АРТИКУЛ_ДЛИННЫЙ', 'SubGroupe', 'КодЕд',\n",
        "       'Поставщик_Имя', 'Тип номенклатуры по умолчанию', 'Вид ставки НДС',\n",
        "       'Способ списания', 'Счет учета запасов', 'Счет учета затрат',\n",
        "       'Способ пополнения', 'Вид маркировки', 'Вид маркируемой продукции ИС МП',\n",
        "       'Обувная продукция', 'Признак предмета расчета',\n",
        "       'Направление деятельности', 'Использовать партии',\n",
        "       'Обязательное заполнение партий', 'Нижняя граница остатков',\n",
        "       'Верхняя граница остатков']].copy(deep=True)\n",
        "#  'Ценовая группа', # в будущем может пригодиться\n",
        "SKUexport.rename(columns={\n",
        "                 'НАИМЕНОВАНИЕ_ДЛИННОЕ' : 'Наименование'\n",
        "                ,'АРТИКУЛ_ДЛИННЫЙ' : 'Артикул'\n",
        "                ,'SubGroupe' : 'Категория'\n",
        "                ,'Тип номенклатуры по умолчанию' : 'ТипНоменклатуры'\n",
        "                ,'Способ списания' : 'МетодОценки'\n",
        "                ,'КодЕд' : 'Единица измерения'\n",
        "                ,'Обязательное заполнение партий' : 'ПроверятьЗаполнениеПартий'\n",
        "                ,'Вид маркируемой продукции ИС МП' : 'ВидПродукцииИС'\n",
        "                ,'Поставщик_Имя' : 'Поставщик'\n",
        "                        },inplace=True)\n",
        "SKUexport = SKUexport.copy(deep=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "pWUxejtPp0C4"
      },
      "outputs": [],
      "source": [
        "# Фрейм SKUexportAll (вся номенклатура из исходника)\n",
        "# Фрейм SKUexportNew (номенклатуры нет в 1с, но есть в исходнике)\n",
        "# Фрейм SKUexportOld (номенклатуры нет в исходнике, но есть в 1с)\n",
        "SKUexportAll = SKUexport.copy(deep=True)\n",
        "SKUexportAll.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        "\n",
        "SKUexportNew = SKUexport.copy(deep=True)\n",
        "SKUexportNew = SKUexportNew\\\n",
        "  .merge(from1c[['Код','Номенклатура']], on='Номенклатура', how='left')\n",
        "SKUexportNew = SKUexportNew[SKUexportNew['Код'].isna()] \n",
        "SKUexportNew.drop(columns=['Код'], inplace= True) # все равно пустая\n",
        "# тут NaN по коду это строки с новыми карточками, вытащим их как раз\n",
        "SKUexportNew.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        " \n",
        "SKUexportOld = SKUexport.copy(deep=True)\n",
        "SKUexportOld = SKUexport\\\n",
        "  .merge(from1c[['Код','Номенклатура']], on='Номенклатура', how='right')\\\n",
        "  .merge(BarNoDup[['SubGroupe','Номенклатура']], on='Номенклатура',how='left')\\\n",
        "\n",
        "SKUexportOld['ТОВАР'] = SKUexportOld['Код'].str[3:].astype('Int64') #код домино\n",
        "SKUexportOld = SKUexportOld[SKUexportOld['SubGroupe'].notna()]#оставить тестовый\n",
        "SKUexportOld = SKUexportOld[SKUexportOld['Наименование'].isna()]\n",
        "SKUexportOld = SKUexportOld[['Номенклатура','SubGroupe']]\n",
        "SKUexportOld = SKUexportOld\\\n",
        "    .merge(from1c[['Недействительна','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(from1c[['Категория','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(from1c[['Наименование','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\n",
        "\n",
        "SKUexportOld.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        "# Все коды из 1с, тут NaN по наименованию это то, что в исходнике не нашлось\n",
        "# выдает просто список кодов. Не убить тестовые раз. Можно достать из\n",
        "# баркодов новую группу и заменить, не удалять их \n",
        "# merge изначально не работал из-за разного столбца \"номенклатура\"\n",
        "# из домино и из 1с, кодировка?\n",
        "\n",
        "# Переименовать Номенклатуру в Код для 1с пришлось после, костыль"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм SKU Update Все строки, где не совпало 1с и Домино\n",
        "SkuUpdate = from1c[['Код Домино', 'Номенклатура', 'Наименование'\n",
        "       ,'Артикул','Категория', 'Поставщик', 'Ссылка.Менеджер (\"Общие\")'\n",
        "       , 'Недействительна']].copy(deep=True)\n",
        "SkuUpdate = SkuUpdate\\\n",
        "  .merge(PriceFrom1c[['Цена','Номенклатура']], on='Номенклатура', how='left')\\\n",
        "  .merge(BarNoDup[['Штрихкод','Номенклатура']], on='Номенклатура', how='left')\n",
        "\n",
        "###############################################################################\n",
        "SkuUpdate = SkuUpdate\\\n",
        "    .merge(SKUexport[['Наименование','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left', indicator=True)\n",
        "SkuUpdate.rename(columns={'_merge': 'merge1'}, inplace=True)\n",
        "SkuUpdate['eq1'] = SkuUpdate['Наименование_y'].str.strip().str.lower()\\\n",
        "                == SkuUpdate['Наименование_x'].str.strip().str.lower()\n",
        "\n",
        "SkuUpdate = SkuUpdate\\\n",
        "    .merge(SKUexport[['Артикул','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left', indicator=True)\n",
        "SkuUpdate.rename(columns={'_merge': 'merge2'}, inplace=True)\n",
        "SkuUpdate['eq2'] = SkuUpdate['Артикул_y'].str.strip().str.lower()\\\n",
        "                == SkuUpdate['Артикул_x'].str.strip().str.lower()\n",
        "\n",
        "SkuUpdate = SkuUpdate\\\n",
        "    .merge(SKUexport[['Категория','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left', indicator=True)\n",
        "SkuUpdate.rename(columns={'_merge': 'merge3'}, inplace=True)\n",
        "SkuUpdate['eq3'] = SkuUpdate['Категория_y'].str.strip().str.lower()\\\n",
        "                == SkuUpdate['Категория_x'].str.strip().str.lower()\n",
        "\n",
        "SkuUpdate = SkuUpdate\\\n",
        "    .merge(SKUexport[['Поставщик','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left', indicator=True)\n",
        "SkuUpdate.rename(columns={'_merge': 'merge4'}, inplace=True)\n",
        "SkuUpdate['eq4'] = SkuUpdate['Категория_y'].str.strip().str.lower()\\\n",
        "                == SkuUpdate['Категория_x'].str.strip().str.lower()\n",
        "\n",
        "SkuUpdate = SkuUpdate\\\n",
        "    .merge(skuDf[['Мен1С','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left', indicator=True)\n",
        "SkuUpdate.rename(columns={'_merge': 'merge5'}, inplace=True)\n",
        "SkuUpdate['eq5']\\\n",
        "            = SkuUpdate['Ссылка.Менеджер (\"Общие\")'].str.strip().str.lower()\\\n",
        "           == SkuUpdate['Мен1С'].str.strip().str.lower()\n",
        "\n",
        "SkuUpdate = SkuUpdate\\\n",
        "    .merge(skuDf[['Цена','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left', indicator=True)\n",
        "SkuUpdate.rename(columns={'_merge': 'merge6'}, inplace=True)\n",
        "SkuUpdate['eq6'] = SkuUpdate['Цена_y'] == SkuUpdate['Цена_x']\n",
        "\n",
        "# Все строки, где не совпало 1с и Домино\n",
        "SkuUpdate['eqAll'] = SkuUpdate['eq1'] * SkuUpdate['eq2'] * SkuUpdate['eq3']\\\n",
        "    * SkuUpdate['eq4'] * SkuUpdate['eq5'] * SkuUpdate['eq6']\n",
        "\n",
        "###############################################################################\n",
        "# Оставляем только совпавшие с актуальной базой Домино\n",
        "SkuUpdate = SkuUpdate.query(\"merge1 == 'both'\")\n",
        "# Оставляем только несовпавшие значения по колонкам с 1С\n",
        "SkuUpdate = SkuUpdate.query(\"eqAll == False\")\n",
        "# Оставляем только нужные колонки\n",
        "SkuUpdate = SkuUpdate[['Номенклатура', 'Штрихкод', 'Наименование_y'\n",
        "    , 'Артикул_y', 'Категория_y', 'Поставщик_y', 'Мен1С', 'Цена_y']]\n",
        "\n",
        "SkuUpdate.rename(columns={\n",
        "                 'Наименование_y' : 'Наименование'\n",
        "                ,'Артикул_y' : 'Артикул'\n",
        "                ,'Категория_y' : 'Категория'\n",
        "                ,'Поставщик_y' : 'Поставщик'\n",
        "                ,'Мен1С' : ' Менеджер'\n",
        "                ,'Цена_y' : 'Цена'\n",
        "                        },inplace=True)   \n",
        "SkuUpdate.insert(loc=3, column='Наименование полное'\n",
        "                       ,value = SkuUpdate['Наименование'])\n"
      ],
      "metadata": {
        "id": "SJP5Z3pLQvcr"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "yI7ATIjAN0Lw"
      },
      "outputs": [],
      "source": [
        "# Фрейм BarcodeExportNew только штрихкода к новым карточкам\n",
        "# Проверять наличие уже их в 1с тогда надо бы сразу\n",
        "BarcodeExportNew = df1[['Номенклатура', 'Штрихкод']].copy(deep=True)\n",
        "BarcodeExportNew.rename(columns={'Номенклатура': 'Код'}, inplace=True)\n",
        "BarcodeExportNew = BarcodeExportNew.merge(SKUexportNew['Код']\\\n",
        "                                          , how='inner')\n",
        "BarcodeExportNew.rename(columns={'Код': 'Номенклатура'}, inplace=True)\n",
        "# Оставить только совпавшие SKUexportNew строки, новый товар\n",
        "# Нюансик, строки без штрихкода дропаются тоже how='inner'                                                                   "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм BarcodeExportMissed таких шк нет в 1с, а коды есть (у живых SKU)\n",
        "BarcodeExportMissed = BarcodeExport.copy(deep=True)\n",
        "BarcodeExportMissed = BarcodeExportMissed.merge(BarFrom1c['Штрихкод']\\\n",
        "                                         ,how='left', indicator=True)\\\n",
        "                                         .query(\"_merge == 'left_only'\")\\\n",
        "                                         .drop('_merge', axis=1)"
      ],
      "metadata": {
        "id": "etNQK3usLT3V"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм BarcodeExportWasted связка код штрихкод 1с, не совпадает с Домино\n",
        "# А также такие штрихкода есть в 1с, а в домино вообще их нет.\n",
        "# Сюда тестовые попадают тоже, не грохнуть их случайно\n",
        "BarcodeExportWasted = BarFrom1c[['Номенклатура', 'Штрихкод'\n",
        "    ,'Номенклатура.Наименование','Номенклатура.Категория']].copy(deep=True)\n",
        "BarcodeExportWasted = BarcodeExportWasted\\\n",
        "  .merge(df1[['Номенклатура','Штрихкод']], on='Штрихкод', how='left')\n",
        "BarcodeExportWasted['Flag']\\\n",
        "     = BarcodeExportWasted['Номенклатура_x']\\\n",
        "    == BarcodeExportWasted['Номенклатура_y']\n",
        "BarcodeExportWasted = BarcodeExportWasted[~BarcodeExportWasted['Flag']]\n",
        "BarcodeExportWasted = BarcodeExportWasted\\\n",
        "    [~BarcodeExportWasted['Номенклатура.Наименование'].str.contains('!ТЕСТ')]\n",
        "BarcodeExportWasted = BarcodeExportWasted[['Штрихкод']]"
      ],
      "metadata": {
        "id": "lzfctOzMMZw0"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "QNKY7DNJkXlm"
      },
      "outputs": [],
      "source": [
        "# Фрейм PriceExport под штатную загрузку розничной цены и менеджера\n",
        "PriceExport\\\n",
        "    = skuDf[['Номенклатура', 'Штрихкод', 'ЦЕНА(ПР)','Мен1С']].copy(deep=True)\n",
        "PriceExport['Штрихкод'] =  PriceExport['Штрихкод'].astype(str)\n",
        "PriceExport.rename(columns={'ЦЕНА(ПР)': 'Цена'}, inplace=True)\n",
        "PriceExport.rename(columns={'Мен1С': 'Менеджер'}, inplace=True)\n",
        "PriceExport['Вид цен'] = 'Розница'\n",
        "PriceExport['Период'] = '31.03.2023'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм batchExport партии номенклатуры все где есть остаток в исходнике\n",
        "batchExport = batch[['Номенклатура', 'Партия',\n",
        "                     'ПОСТАВЩИК', 'ДОГ']].copy(deep=True)\n",
        "batchExport = batchExport\\\n",
        "    .merge(batch_statusDf[['СтатусОплаты1С','ДОГ']], on='ДОГ', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Статус_НДС','ПОСТАВЩИК']]\\\n",
        "                        , on='ПОСТАВЩИК', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Имя','ПОСТАВЩИК']]\\\n",
        "                        , on='ПОСТАВЩИК', how='left')\n",
        "batchExport['Наименование'] = batchExport['Партия'].astype(str)\n",
        "batchExport['Статус'] = batchExport['СтатусОплаты1С']\n",
        "batchExport['Владелец партии'] =batchExport['Поставщик_Имя']\n",
        "batchExport['Налогообложение'] =batchExport['Поставщик_Статус_НДС']\n",
        "\n",
        "batchExport = batchExport[['Номенклатура','Наименование','Статус' \n",
        "                            ,'Владелец партии','Налогообложение',]]"
      ],
      "metadata": {
        "id": "g7BCmEHs7a18"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм batchExportNewDelete batchExportNewInsert\n",
        "# Новые одним потоком добавить не удается, оно старые перезаписывает\n",
        "# как выход, удалить перезаписанные, потом перезалить по этим базовым\n",
        "batchExportNew = batchExport.copy(deep=True)\n",
        "batchExportNew = batchExportNew.merge(batch_from1c_df['Наименование']\\\n",
        "                                      ,how='left', indicator=True)\\\n",
        "                                      .query(\"_merge == 'left_only'\")\\\n",
        "                                      .drop('_merge', axis=1)\n",
        "###############################################################################\n",
        "\n",
        "# Сначала удаляем партии по этим базовым \n",
        "# ИР, цикл в несколько итераций, ключ поиска по базовым карточкам                                   \n",
        "batchExportNewDelete =  batchExportNew.copy(deep=True)\n",
        "batchExportNewDelete = batchExportNewDelete\\\n",
        "                     .drop_duplicates(subset=['Номенклатура'])\n",
        "batchExportNewDelete = batchExportNewDelete\\\n",
        "                     .merge(batch_from1c_df[['Наименование','Номенклатура']]\\\n",
        "                     , on='Номенклатура', how='left')\n",
        "batchExportNewDelete.dropna(subset=['Наименование_y'], inplace = True)    \n",
        "batchExportNewDelete = batchExportNewDelete[['Номенклатура','Наименование_y']] \n",
        "batchExportNewDelete\\\n",
        "    .rename(columns={'Наименование_y': 'Наименование'}, inplace=True)\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "# Потом вгружаем все партии по этим базовым, галку ОБНОВЛЯТЬ снимаем!, ток новые\n",
        "batchExportNewInsert =  batchExportNew.copy(deep=True)\n",
        "batchExportNewInsert = batchExportNewInsert\\\n",
        "                     .drop_duplicates(subset=['Номенклатура'])\n",
        "batchExportNewInsert = batchExportNewInsert\\\n",
        "                     .merge(batchExport[['Наименование','Номенклатура']]\\\n",
        "                     , on='Номенклатура', how='left')\n",
        "batchExportNewInsert = batchExportNewInsert[['Номенклатура','Наименование_y'\n",
        "                             , 'Статус', 'Владелец партии','Налогообложение',]]\n",
        "batchExportNewInsert\\\n",
        "    .rename(columns={'Наименование_y': 'Наименование'}, inplace=True)    \n",
        "\n",
        "###############################################################################\n",
        "\n",
        "# Партии, которых есть в 1с, а в домине уже остатка нет\n",
        "\n",
        "batchExportOldDelete = batch_from1c_df.copy(deep=True)     \n",
        "batchExportOldDelete = batchExportOldDelete\\\n",
        "                      .merge(batchExport['Наименование']\\\n",
        "                      ,how='left', indicator=True)\\\n",
        "                      .query(\"_merge == 'left_only'\")\\\n",
        "                      .drop('_merge', axis=1)   \n",
        "batchExportOldDelete = batchExportOldDelete[['Номенклатура','Наименование']]               "
      ],
      "metadata": {
        "id": "mFCpEa9WL7-q"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Фрейм bdfExport остатки по партиям\n",
        "# Комиссия отдельно сделать\n",
        "# Ошибка если единицы из домина не по списку приходят, case censitive в.т.ч\n",
        "# Лечить в Домине не дожидаясь перитонита\n",
        "# в Домине не лечится, возьмем из базовых из исходника\n",
        "# Допилить проверку ошибок\n",
        "bdf = batch.copy(deep=True)\n",
        "bdf['Партия'] = bdf['Партия'].astype(str)\n",
        "\n",
        "input_rows = bdf.shape[0]\n",
        "input_qtt = bdf['ИСХ_КОЛИЧ'].sum().round(2)\n",
        "input_sum = bdf['СебестРуб.3'].sum().round(2)\n",
        "\n",
        "bdf = bdf\\\n",
        "    .merge(df2[['ЕИ','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['Штрихкод','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(BarNoDup[['SubGroupe','Номенклатура']]\\\n",
        "           , on='Номенклатура', how='left')\\\n",
        "    .merge(suppliersDf[['Поставщик_Имя','ПОСТАВЩИК']]\\\n",
        "           , on='ПОСТАВЩИК', how='left')\\\n",
        "    .merge(batch_statusDf[['ВидОперации','ДОГ']]\\\n",
        "           , on='ДОГ', how='left')\\\n",
        "    .merge(unitsDf[['КодЕд','ЕИ']], on='ЕИ', how='left')\\\n",
        "    .merge(unitsDf[['1сКрЕИ','ЕИ']], on='ЕИ', how='left')   \n",
        "\n",
        "bdf = bdf.sort_values(by=['ВидОперации'])\n",
        "bdf['Контрагент'] = bdf['Поставщик_Имя']\n",
        "bdf['Единица измерения'] = bdf['1сКрЕИ']\n",
        "\n",
        "bdf['Договор'] = 'Основной договор'   \n",
        "bdf[['1эт остаток', '2эт остаток','скл1 остаток', 'б/н остаток',\n",
        "           'брак остаток', 'ИСХ_КОЛИЧ','СебестРуб.3']] = bdf[['1эт остаток', \n",
        "           '2эт остаток','скл1 остаток', 'б/н остаток',\n",
        "           'брак остаток', 'ИСХ_КОЛИЧ','СебестРуб.3']].fillna(0)    \n",
        "\n",
        "bdf['хозу остаток'] =  bdf['ИСХ_КОЛИЧ'] - bdf['1эт остаток']\\\n",
        "                     - bdf['2эт остаток'] - bdf['скл1 остаток']\\\n",
        "                     - bdf['б/н остаток'] - bdf['брак остаток']  \n",
        "bdf['Себестоимость'] = bdf['СебестРуб.3'] / bdf['ИСХ_КОЛИЧ']\n",
        "\n",
        "serv_rows = bdf[bdf['ГРУППА'] == '!!УСЛУГИ'].index.value_counts().sum()\n",
        "serv_qtt = bdf[bdf['ГРУППА'] == '!!УСЛУГИ']['ИСХ_КОЛИЧ'].sum().round(2) \n",
        "serv_sum = bdf[bdf['ГРУППА'] == '!!УСЛУГИ']['СебестРуб.3'].sum().round(2)\n",
        "# У услуг нет остатка\n",
        "\n",
        "bdf.drop(bdf[(bdf['ГРУППА'] == '!!УСЛУГИ')].index, inplace=True)\n",
        "\n",
        "# тут мы сцепляем остатки по подразделениям в одну таблицу\n",
        "batchSum = pd.DataFrame()\n",
        "storage_domino = warehousesDf['Отдел'].values\n",
        "storage_1c = warehousesDf['СтруктурнаяЕдиница'].values\n",
        "i = 0\n",
        "z = 0\n",
        "for x in storage_domino:\n",
        "    # print('step ', i) # отладочное\n",
        "    # print('x=',x)\n",
        "    # print(storage_1c[i])\n",
        "    bdfTmp = bdf[bdf[x] != 0].copy()\n",
        "    bdfTmp['СтруктурнаяЕдиница'] = storage_1c[i] #Склад 1c\n",
        "    bdfTmp['Количество'] = bdfTmp[x]\n",
        "    bdfTmp['Сумма'] = bdfTmp['Количество'] * bdfTmp['Себестоимость']\n",
        "    z = z + bdfTmp.shape[0]\n",
        "    # print(bdfTmp.shape[0], 'rows')\n",
        "    # print(z, 'rowsSum')\n",
        "    batchSum = pd.concat([batchSum, bdfTmp], ignore_index= True)\n",
        "    i = i + 1\n",
        "##############################################################################\n",
        "bdfExportAll = batchSum[['Номенклатура', 'Партия', 'Количество',\n",
        "                      'Единица измерения', 'Сумма',\n",
        "                      'СтруктурнаяЕдиница', 'Контрагент',  # 'Себестоимость',\n",
        "                      'ВидОперации', 'Договор'              \n",
        "                     ]].copy()\n",
        "\n",
        "output_rows = batchSum.shape[0]\n",
        "output_qtt = batchSum['Количество'].sum().round(2)\n",
        "output_sum = batchSum['Сумма'].sum().round(2)\n",
        "# Загрузить минусовые комиссия как плюсы  ####################################\n",
        "bdfExportNegativeTitleСommission = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.notna() & Количество < 0', engine='python')\n",
        "bdfExportNegativeTitleСommission['Количество'] = \\\n",
        "                         bdfExportNegativeTitleСommission['Количество'].abs()\n",
        "bdfExportNegativeTitleСommission['Сумма'] = \\\n",
        "                         bdfExportNegativeTitleСommission['Сумма'].abs()\n",
        "# Загрузить минусовые свои как плюсы  ########################################\n",
        "bdfExportNegativeTitlePurchased = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.isna() & Количество < 0', engine='python')\n",
        "bdfExportNegativeTitlePurchased['Количество'] = \\\n",
        "                         bdfExportNegativeTitlePurchased['Количество'].abs()\n",
        "bdfExportNegativeTitlePurchased['Сумма'] = \\\n",
        "                         bdfExportNegativeTitlePurchased['Сумма'].abs()\n",
        "# Для списать все в двойном размере, подразделение????####################### \n",
        "bdfExportNegativeTitleAllx2 = bdfExportAll.copy(deep=True).query\\\n",
        "                                        ('Количество < 0', engine='python')\n",
        "bdfExportNegativeTitleAllx2['Количество'] = \\\n",
        "                         bdfExportNegativeTitleAllx2['Количество'].abs() * 2\n",
        "bdfExportNegativeTitleAllx2['Сумма'] = \\\n",
        "                         bdfExportNegativeTitleAllx2['Сумма'].abs() * 2\n",
        "# Плюсовые комиссия только положительные  ###################################\n",
        "bdfExportPositiveTitleСommission = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.notna() & Количество > 0', engine='python')\n",
        "# Плюсовые свои только положительные   ######################################\n",
        "bdfExportPositiveTitlePurchased = bdfExportAll.copy(deep=True).query\\\n",
        "                    ('ВидОперации.isna() & Количество > 0', engine='python')\n",
        "# Плюсовые комиссия все подряд по модулю  ###################################\n",
        "bdfExportPositiveTitleСommissionAll = bdfExportAll.copy(deep=True).query\\\n",
        "                                   ('ВидОперации.notna()', engine='python')\n",
        "bdfExportPositiveTitleСommissionAll['Количество'] = \\\n",
        "                         bdfExportPositiveTitleСommissionAll['Количество'].abs()\n",
        "bdfExportPositiveTitleСommissionAll['Сумма'] = \\\n",
        "                         bdfExportPositiveTitleСommissionAll['Сумма'].abs()\n",
        "# Плюсовые свои все подряд по модулю      ###################################\n",
        "bdfExportPositiveTitlePurchasedAll = bdfExportAll.copy(deep=True).query\\\n",
        "                                   ('ВидОперации.isna()', engine='python')\n",
        "bdfExportPositiveTitlePurchasedAll['Количество'] = \\\n",
        "                         bdfExportPositiveTitlePurchasedAll['Количество'].abs()\n",
        "bdfExportPositiveTitlePurchasedAll['Сумма'] = \\\n",
        "                         bdfExportPositiveTitlePurchasedAll['Сумма'].abs()\n",
        "\n",
        "##############################################################################\n",
        "output1_rows = bdfExportNegativeTitleСommission.shape[0]\n",
        "output1_qtt = bdfExportNegativeTitleСommission['Количество'].sum().round(2)\n",
        "output1_sum = bdfExportNegativeTitleСommission['Сумма'].sum().round(2)\n",
        "\n",
        "output2_rows = bdfExportNegativeTitlePurchased.shape[0]\n",
        "output2_qtt = bdfExportNegativeTitlePurchased['Количество'].sum().round(2)\n",
        "output2_sum = bdfExportNegativeTitlePurchased['Сумма'].sum().round(2)\n",
        "\n",
        "output3_rows = bdfExportPositiveTitleСommission.shape[0]\n",
        "output3_qtt = bdfExportPositiveTitleСommission['Количество'].sum().round(2)\n",
        "output3_sum = bdfExportPositiveTitleСommission['Сумма'].sum().round(2)\n",
        "\n",
        "output4_rows = bdfExportPositiveTitlePurchased.shape[0]\n",
        "output4_qtt = bdfExportPositiveTitlePurchased['Количество'].sum().round(2)\n",
        "output4_sum = bdfExportPositiveTitlePurchased['Сумма'].sum().round(2)\n",
        "\n",
        "check = pd.DataFrame({'Rows': [input_rows, serv_rows, output_rows,\n",
        "                      output1_rows, output2_rows, output3_rows, output4_rows],\n",
        "                     'quantity': [input_qtt, serv_qtt, output_qtt,\n",
        "                     output1_qtt, output2_qtt, output3_qtt, output4_qtt],\n",
        "                     'sum': [input_sum, serv_sum, output_sum,\n",
        "                            output1_sum, output2_sum, output3_sum, output4_sum]\n",
        "                      },index=['Input', 'Service', 'Output',\n",
        "                         '-com', '-our', '+com', '+our',       ])\n",
        "\n",
        "check.loc['Check (rows is OK)'] = check.loc['Output'] -\\\n",
        "                              (check.loc['Input'] - check.loc['Service']) \n",
        "check.loc['Check (+-= OK)'] =-check.loc['-com'] - check.loc['-our']\\\n",
        "                             +check.loc['+com'] + check.loc['+our']\\\n",
        "                             -check.loc['Output']                                                                   "
      ],
      "metadata": {
        "id": "BVLDGODBtdlB"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MoneyDf = MoneyInputDf.copy(deep=True)\n",
        "MoneyDf['Поставщик_Имя'] = MoneyDf['Имя партнера']\n",
        "MoneyDf['Признак Аванса'] =\\\n",
        "    ['ДА' if x < 0 else 'НЕТ' for x in MoneyDf['Общий долг']]\n",
        "MoneyDf['Договор'] = 'Основной договор'   \n",
        "MoneyDf['Контрагент'] = MoneyDf['Имя партнера']   \n",
        "MoneyDf['Сумма'] = MoneyDf['Общий долг'].abs()  \n",
        "MoneyDf['Сумма (вал)'] = MoneyDf['Сумма'] \n",
        "MoneyDf = MoneyDf.merge(suppliersDf['Поставщик_Имя'], how='right')\n",
        "MoneyDf = MoneyDf.drop_duplicates(subset=['Имя партнера'])\n",
        "MoneyDf = MoneyDf[MoneyDf['Сумма'] != 0]\n",
        "tails_cut = 20  #убрать мелкий долг меньше 20р\n",
        "drorred_suppliers = len(MoneyDf[MoneyDf['Сумма'] <= tails_cut])\n",
        "MoneyDf = MoneyDf[MoneyDf['Сумма'] > tails_cut]  \n",
        "MoneyDfExport = MoneyDf[['Признак Аванса', 'Договор',\n",
        "                         'Контрагент', 'Сумма', 'Сумма (вал)']]"
      ],
      "metadata": {
        "id": "cOnU1qclqK-W"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP3UKKl1awHp"
      },
      "source": [
        "## Блок проверки констситентности\n",
        "## Если проверка не прошла, вылезет ошибка, блок записи не запустится\n",
        "Список возможных глюков на входе:\n",
        "*   Единицы измерения не из списка, хранятся в партиях, нужно базовые в партии перезаписывать чтобы накатился фикс. А они не записываются, база не дает, я в восхищении!\n",
        "*   Непечатываемые символы из Домино (Code31) в частности Ищется поиском в экселе =НАЙТИ(СИМВОЛ(33);A1)\n",
        "*   Чистить штрихкоды в 1с те, которые поменялись между карточками, чтобы всю пачку не грузить и дублей не было, пустые тоже\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "sfBTvB3pb22-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e3119ca-cf91-4e39-aad5-f6e449b1752f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "OK Исходник на входе 33856 строк совпадает по длине с итоговым 33856 строк\n",
            "OK 0 строк без поставщика\n",
            "OK 0 строк без единицы измерения\n",
            "На входе df2 исходник текущий     строк: 33856\n",
            "Output BarcodeExport         строк: 41474\n",
            "Output BarcodeExportNew      строк: 0\n",
            "Output BarcodeExpMissed      строк: 0\n",
            "Output BarcodeExpWasted      строк: 0\n",
            "Output batchExportAll        строк: 28545\n",
            "Output batchExportNewDelete  строк: 7\n",
            "Output batchExportNewInsert  строк: 922\n",
            "Output batchExportOldDelete  строк: 0\n",
            "Output bdfExport(8)          строк: 29053\n",
            "Output PriceExport           строк: 33856\n",
            "Output SKUexportAll          строк: 33856\n",
            "Output SKUexportNew          строк: 0\n",
            "Output SKUexportOld          строк: 2503\n",
            "Output SkuUpdate             строк: 7566\n",
            "Output MoneyDfExport         строк: 72\n",
            "В балансах поставщиков обрезаны данные меньше 20р. 23 строк\n",
            "--------------------------------------------------------------------------------\n",
            "Проверка выгрузки партий\n",
            "--------------------------------------------------------------------------------\n",
            "                       Rows   quantity          sum\n",
            "Input               28545.0  250677.43  28690533.32\n",
            "Service                 3.0   -1509.00       -15.09\n",
            "Output              29053.0  252186.43  28690548.41\n",
            "-com                    3.0       3.00      1000.96\n",
            "-our                  351.0    1185.29    116169.94\n",
            "+com                  400.0    1198.00    741609.95\n",
            "+our                28299.0  252176.72  28066109.36\n",
            "Check (rows is OK)    511.0       0.00         0.00\n",
            "Check (+-= OK)       -708.0       0.00         0.00\n",
            "--------------------------------------------------------------------------------\n",
            "OK Qtt       0.0\n",
            "OK Sum       0.0\n",
            "OK TotalQtt  0.0\n",
            "OK TotalSum  0.0\n",
            "--------------------------------------------------------------------------------\n",
            "OK BarFrom1c Qtt    strings:  True\n",
            "OK BarFrom1c unique strings:  True\n",
            "OK Совпали Штрихкода из 1с с Домино:  True\n"
          ]
        }
      ],
      "source": [
        "# %whos DataFrame\n",
        "print('-'*80)\n",
        "inputLen, outputLen = len(df2), len(SKUexportAll)\n",
        "if inputLen == outputLen:\n",
        "    print(f'OK Исходник на входе {inputLen} строк совпадает по длине '\n",
        "          f'с итоговым {outputLen} строк')\n",
        "else:\n",
        "    raise Exception(f'Количество строк на входе и выходе не совпадает на:'\n",
        "                    f'{inputLen - outputLen} строк')\n",
        "\n",
        "noSupplier = SKUexportAll['Поставщик'].isna().sum()   \n",
        "if noSupplier == 0:\n",
        "    print(f'OK {noSupplier} строк без поставщика')\n",
        "else:\n",
        "    raise Exception(f'{noSupplier} строк без поставщика')\n",
        "\n",
        "noUnit = SKUexportAll['Единица измерения'].isna().sum() \n",
        "if noUnit == 0:\n",
        "    print(f'OK {noUnit} строк без единицы измерения')\n",
        "else:\n",
        "    raise Exception(f'{noUnit} строк без единицы измерения')\n",
        "\n",
        "print ('На входе df2 исходник текущий     строк:',df2.shape[0])\n",
        "print ('Output BarcodeExport         строк:',BarcodeExport.shape[0])\n",
        "print ('Output BarcodeExportNew      строк:',BarcodeExportNew.shape[0])\n",
        "print ('Output BarcodeExpMissed      строк:',BarcodeExportMissed.shape[0])\n",
        "print ('Output BarcodeExpWasted      строк:',BarcodeExportWasted.shape[0])\n",
        "print ('Output batchExportAll        строк:',batchExport.shape[0])\n",
        "print ('Output batchExportNewDelete  строк:',batchExportNewDelete.shape[0])\n",
        "print ('Output batchExportNewInsert  строк:',batchExportNewInsert.shape[0])\n",
        "print ('Output batchExportOldDelete  строк:',batchExportOldDelete.shape[0])\n",
        "print ('Output bdfExport(8)          строк:',bdfExportAll.shape[0])\n",
        "print ('Output PriceExport           строк:',PriceExport.shape[0])\n",
        "print ('Output SKUexportAll          строк:',SKUexportAll.shape[0])\n",
        "print ('Output SKUexportNew          строк:',SKUexportNew.shape[0])\n",
        "print ('Output SKUexportOld          строк:',SKUexportOld.shape[0])\n",
        "print ('Output SkuUpdate             строк:',SkuUpdate.shape[0])\n",
        "print ('Output MoneyDfExport         строк:',MoneyDfExport.shape[0])\n",
        "\n",
        "if drorred_suppliers != 0:\n",
        "    print(f'В балансах поставщиков обрезаны данные меньше {tails_cut}р. '\n",
        "          f'{drorred_suppliers} строк')\n",
        "\n",
        "print('-'*80)\n",
        "print ('Проверка выгрузки партий')\n",
        "print('-'*80)\n",
        "print(check)\n",
        "print('-'*80)\n",
        "CheckQtt = check['quantity'][-2]\n",
        "CheckSum = check['sum'][-2]\n",
        "TotalQtt = check['quantity'][-1]\n",
        "TotalSum = check['sum'][-1]\n",
        "TotalCheck = CheckQtt + CheckSum + TotalQtt + TotalSum\n",
        "if TotalCheck == 0:\n",
        "    print(f'OK Qtt      ', CheckQtt)#Строк больше на совпавшие по отделам запасы\n",
        "    print(f'OK Sum      ', CheckSum)\n",
        "    print(f'OK TotalQtt ', TotalQtt)#Строк меньше на количество отрицательных\n",
        "    print(f'OK TotalSum ', TotalSum)#Это только в чеке, так их столько же\n",
        "else:\n",
        "    raise Exception(f'{CheckQtt},{CheckQtt},{TotalQtt},{TotalSum}\\\n",
        "     не совпали строки по партиям')\n",
        "print('-'*80)\n",
        "is_equal_barcodes_from_1c_strings_count\\\n",
        "    = BarFrom1c['Штрихкод'].nunique() == BarFrom1c.shape[0]\n",
        "is_unique_barcodes_from_1c = BarFrom1c['Штрихкод'].is_unique\n",
        "\n",
        "if  is_equal_barcodes_from_1c_strings_count & is_unique_barcodes_from_1c :   \n",
        "    print(f'OK BarFrom1c Qtt    strings: ',\n",
        "          is_equal_barcodes_from_1c_strings_count)\n",
        "    print(f'OK BarFrom1c unique strings: ', is_unique_barcodes_from_1c)\n",
        "else:\n",
        "    print(f'Not OK BarFrom1c Qtt    strings: ',\n",
        "          is_equal_barcodes_from_1c_strings_count)\n",
        "    print(f'Not OK BarFrom1c unique strings: ', is_unique_barcodes_from_1c)\n",
        "\n",
        "if BarcodeExportWasted.shape[0] > 0 :\n",
        "    print ('Not OK Не совпадают штрихкода из 1с с Домино, удали их, строк: '\n",
        "                                                  ,BarcodeExportWasted.shape[0])\n",
        "else: \n",
        "    print ('OK Совпали Штрихкода из 1с с Домино: '\n",
        "                             ,BarcodeExportWasted.shape[0] == 0)  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_iTMisY3oXq"
      },
      "source": [
        "##Блок записи в файлы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "XfNisczxGgE-"
      },
      "outputs": [],
      "source": [
        "# engine менять обязательно, иначе не сохраняет эксельки\n",
        "# ВЫГРУЖАЕТ фрейм BarcodeExport в BarcodesAll.xlsx  \n",
        "file_name = 'BarcodesAll'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "BarcodeExport.to_excel(file_name, index=False, header=True\\\n",
        "                       , freeze_panes=(1,1), engine='xlsxwriter') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "_gExEQ21oXeF"
      },
      "outputs": [],
      "source": [
        "# ВЫГРУЖАЕТ фрейм BarcodeExportNew в BarcodesNew.xlsx  \n",
        "file_name = 'BarcodesNew'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "BarcodeExportNew.to_excel(file_name, index=False, header=True\\\n",
        "                       , freeze_panes=(1,1), engine='xlsxwriter') "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ВЫГРУЖАЕТ фрейм BarcodeExportMissed в BarcodesMissed.xlsx  \n",
        "file_name = 'BarcodesMissed'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "BarcodeExportMissed.to_excel(file_name, index=False, header=True\\\n",
        "                       , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "h0wo2OlGbu_B"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ВЫГРУЖАЕТ фрейм BarcodeExportWasted в BarcodeWasted.xlsx  \n",
        "file_name = 'BarcodesWasted'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "BarcodeExportWasted.to_excel(file_name, index=False, header=True\\\n",
        "                       , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "Q9nyPDr8xhNq"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "YvVjCpiOli1P"
      },
      "outputs": [],
      "source": [
        "# ВЫГРУЖАЕТ фрейм PriceExport в Price.xlsx  \n",
        "file_name = 'Price'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "PriceExport.to_excel(file_name, index=False, header=True\\\n",
        "                     , freeze_panes=(1,1), engine='xlsxwriter') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "i6siTlCh7hZx"
      },
      "outputs": [],
      "source": [
        "# Выгружает Фрейм SKUexportAll в SkuAll.xlsx \n",
        "# Справочник всех товаров из исходника для первичного импорта в 1С\n",
        "file_name = 'SkuAll'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SKUexportAll.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "ycFrP3N239m8"
      },
      "outputs": [],
      "source": [
        "# Выгружает Фрейм SKUexportNew в SkuNew.xlsx \n",
        "# Справочник новых товаров из исходника для импорта в 1С\n",
        "file_name = 'SkuNew'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SKUexportNew.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "0WlJktT1D_pi"
      },
      "outputs": [],
      "source": [
        "# Выгружает Фрейм SKUexportOld в SkuOld.xlsx \n",
        "# Справочник новых товаров из исходника для импорта в 1С\n",
        "file_name = 'SkuOld'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SKUexportOld.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм SkuUpdate в SkuUpdate.xlsx \n",
        "# Справочник новых товаров из исходника для импорта в 1С\n",
        "file_name = 'SkuUpdate'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "SkuUpdate.to_excel(file_name, index=False, header=True\\\n",
        "                      , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "cOPoU8lRPPzZ"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм batchExport в batchExportAll.xlsx\n",
        "# Справочник партий, xlsxwriter партии жрет как числа, лечится .astype(str)\n",
        "file_name = 'batchExportAll'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "batchExport.to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "DwRV5BidGHpO"
      },
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм batchExportNewInsert в batchExportNewInsert.xlsx\n",
        "# Справочник партий, xlsxwriter партии жрет как числа, лечится .astype(str)\n",
        "file_name = 'batchExportNewInsert'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "batchExportNewInsert.to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "Xyh1QI00VJZW"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм batchExportNewDelete в batchExportNewDelete.xlsx\n",
        "# Справочник партий, xlsxwriter партии жрет как числа, лечится .astype(str)\n",
        "file_name = 'batchExportNewDelete'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "batchExportNewDelete.to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "NJ8cswzT4v7V"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм batchExportOldDeletee в batchExportOldDelete.xlsx\n",
        "# Справочник партий, xlsxwriter партии жрет как числа, лечится .astype(str)\n",
        "file_name = 'batchExportOldDelete'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "batchExportOldDelete.to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "XfVe81KpDLou"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает # Фреймы bdfExport в Export.xlsx\n",
        "# остатки по партиям\n",
        "dfList = ['bdfExportAll', 'bdfExportNegativeTitlePurchased',\n",
        "   'bdfExportNegativeTitleСommission', 'bdfExportPositiveTitlePurchased',\n",
        "   'bdfExportPositiveTitleСommission', 'bdfExportNegativeTitleAllx2',\n",
        "   'bdfExportPositiveTitleСommissionAll', 'bdfExportPositiveTitlePurchasedAll']\n",
        "fileList =  [s.replace('bdfExport','Export') for s in dfList]\n",
        "\n",
        "i = 0\n",
        "for x in dfList:\n",
        "    file_name = fileList[i]\n",
        "    file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "    locals()[x].to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "hyKdWT4Fymg2"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Выгружает Фрейм MoneyDfExport в Suppliers_Balance.xlsx\n",
        "file_name = 'Suppliers_Balance'\n",
        "file_name = ''.join((output_path, file_name, time_now, to_xlsx))\n",
        "MoneyDfExport.to_excel(file_name, index=False, header=True\\\n",
        "                    , freeze_panes=(1,1), engine='xlsxwriter')"
      ],
      "metadata": {
        "id": "8pi_6cKG3mve"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwgHaoJxgBCM"
      },
      "source": [
        " Шпаргалка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "id": "i5M9YghuvLz8",
        "cellView": "code"
      },
      "outputs": [],
      "source": [
        "#@title ШПАРГАЛКА\n",
        "\n",
        "# df.columns\n",
        "# df.info()\n",
        "# df.dtypes\n",
        "# df.describe()\n",
        "# df['ТОВАР'] #одна колонка\n",
        "# df[['ТОВАР','1эт остаток','2эт остаток']] #3 колонки\n",
        "# df['ТОВАР'].hist #гистограмма\n",
        "# df['SubGroupe'].value_counts() # подсчет уникальных значений\n",
        "# df['SubGroupe'].value_counts(dropna=False) #включая пустые\n",
        "# q = df['Продано'].quantile(0.25)\n",
        "# df[df['Продано'] < q]\n",
        "# BarcodeExport[:10].to_csv #первые 10\n",
        "# df[df2['1эт остаток'].notna()]\n",
        "# df = skuDf[skuDf['Счет учета затрат'].isna()] \n",
        "# df = skuDf[skuDf['Вид маркируемой продукции ИС МП'].notna()] \n",
        "# df['SubGroupe'].value_counts(dropna=False)\n",
        "# skuDf.groupby('В группе',dropna=False)['РозницаРуб'].agg(['count','sum','mean']).sort_values(by='sum', ascending=False)\n",
        "# BarcodeExport['ТОВАР'] = BarcodeExport['ТОВАР'].astype('Int64') \n",
        "# batch['ТОВАР'] = batch['Партия'].astype('Float64').astype('Int64') #перевод партии сначала из текста с точкой в флоат, потом в инт\n",
        "# df3=df1.loc[~df['a'].isin(df2['a'])] #вычесть строки одной из другой тоже способ\n",
        "# df[df[\"col\"]. str.contains (\" this string \")] поиск в базе 'unicode_escape'\n",
        "# BarcodeExport['Номенклатура'] = 'ДМ-' + BarcodeExport['ТОВАР'].apply('{:0>8} '. format).astype (str) #приклеить префикс\n",
        "# bdf.groupby('ГРУППА',dropna=False)['ИСХ_КОЛИЧ'].agg(['count','sum']).sort_values(by='ГРУППА', ascending=True)\n",
        "# Таблица не мерджится тк в 1с всосали все подгруппы в верхнем регистре\n",
        "# df_address['country_lower'] = df_address['Country'].str.lower()\n",
        "\n",
        "# ??pd.DataFrame.to_excel\n",
        "# find = df2[df2['НАИМЕНОВАНИЕ'].str.contains('| '.join('unicode_escape'))]\n",
        "# find = skuDf[skuDf['НАИМЕНОВАНИЕ'].str.contains('САМОРЕЗ')]\n",
        "# ??pd.DataFrame.to_excel\n",
        "# df1 = df1.replace('unicode_escape',' ', regex=True) # В Теории это лечит непечатные символы, ток непонятно, работает ли. Не работает\n",
        "# !pip install xlsxwriter #for xlsxwriter as engine\n",
        "# print ('Я дошёл до конца и выполнился')\n",
        "\n",
        "#BarcodeExportWasted = BarcodeExportWasted.query('Номенклатура.Наименование.str.upper.contains(\"!ТЕСТ\")', engine='python') #нихт фунциклирен возможно из-за точки в имени колонки\n",
        "# df[df['A'].str.contains(\"hello\")]\n",
        "# df1.query('col.str.contains(\"foo\")', engine='python')\n",
        "# df[df['A'].str.contains(\"Hello|Britain\")==True]\n",
        "# batchExportOldDelete.groupby(['_merge'],dropna=False)['_merge'].count()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1KOVCr5p7q42XXkXEguS84fU3KY1Taj5v",
      "authorship_tag": "ABX9TyPYJa7cEvVsLZATqscjOywC",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}